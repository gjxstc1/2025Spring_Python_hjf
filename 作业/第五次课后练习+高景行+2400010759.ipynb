{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五次课后练习 之一"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**负责助教：朱轩宇**\n",
    "\n",
    "<span style=\"color:red; font-weight:bold;\">请将作业文件命名为 第五次课后练习+姓名+学号.ipynb, 例如 第五次课后练习+张三+1000000000.ipynb</span>\n",
    "\n",
    "<span style=\"color:red; font-weight:bold;\">在作业过程中觉得有心得或者自己拓展学习到有价值内容的，可以在文件名最后加一个#号。例如第五次课后练习+张三+1000000000+#.ipynb</span>\n",
    "\n",
    "<span style=\"color:red; font-weight:bold;\">本次课同时发布课后练习和选做题，提交时请注意区分提交通道</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第零部分 代码理解\n",
    "\n",
    "请认真阅读代码，理解代码的功能，先写出预想的结果。运行并检验结果是否如预期。如果不如预期，请分析理解其中的原因"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.1** 多进程编程，进程池，进程间通讯\n",
    "    阅读理解下面代码，观察四次运行的结果，解释出现这个结果的原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这段代码使用了multiprocessing模块来实现多进程任务处理。主要功能是通过多个工作进程（CustomWorker）从任务队列中获取任务，处理任务后将结果放入结果队列。主进程负责管理任务队列、结果队列以及进程池的创建和销毁。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting multiprocessing_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multiprocessing_script.py\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "#`Manager`类是Python `multiprocessing`模块中的一个工具，用于创建可以在多个进程之间\n",
    "#共享的对象（如列表、字典、队列等），简化了进程间数据共享和通信的复杂性。\n",
    "from multiprocessing import Pool, Manager\n",
    "\n",
    "# 该类封装了工作进程的逻辑，包括任务处理、结果返回等。\n",
    "# run方法是一个无限循环，从任务队列中获取任务并处理，直到接收到TERMINATE信号。\n",
    "class CustomWorker:\n",
    "    def __init__(self, worker_id, task_queue, result_queue, config):\n",
    "        self.worker_id = worker_id\n",
    "        self.task_queue = task_queue\n",
    "        self.result_queue = result_queue\n",
    "        self.__secret_key = config['key']\n",
    "        self.__mode = config['mode']\n",
    "\n",
    "    def run(self):\n",
    "        # print(f\"Worker {self.worker_id} started with mode {self.__mode}\")\n",
    "        while True:\n",
    "            try:\n",
    "                task = self.task_queue.get()\n",
    "                if task == 'TERMINATE':\n",
    "                    # print(f\"Worker {self.worker_id} terminating\")\n",
    "                    break\n",
    "                result = self.__process(task)\n",
    "                self.result_queue.put({'worker': self.worker_id, 'result': result, 'task': task})\n",
    "            except Exception as e:\n",
    "                self.result_queue.put({'worker': self.worker_id, 'error': str(e), 'task': task})\n",
    "\n",
    "    # 会根据具体每个worker实例的mode对输入的task做不同的操作\n",
    "    def __process(self, task):\n",
    "        if self.__mode == 'encrypt':\n",
    "            return f\"{task}_{self.__secret_key}\"   # 拼接输入的密码\n",
    "        elif self.__mode == 'hash':\n",
    "            return hash(task + self.__secret_key)  # hash输入的密码\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode\")\n",
    "\n",
    "# 创建CustomWorker实例并调用其run方法。\n",
    "# 每个工作进程根据其ID的奇偶生成不同的配置（encrypt和hash）。\n",
    "def worker_process(task_queue, result_queue):\n",
    "    worker_id = multiprocessing.current_process()._identity[0]\n",
    "    config = {\n",
    "        'key': f\"KEY{worker_id}\",\n",
    "        'mode': 'encrypt' if worker_id % 2 == 0 else 'hash'\n",
    "    }\n",
    "    worker = CustomWorker(worker_id, task_queue, result_queue, config)\n",
    "    worker.run()  \n",
    "\n",
    "def main():\n",
    "    manager = Manager()\n",
    "    task_queue = manager.Queue()    # 任务队列\n",
    "    result_queue = manager.Queue()  # 结果队列\n",
    "\n",
    "    pool_size = 2  # 进程池大小\n",
    "     \n",
    "    expected_tasks = 5  # 期望处理的任务数\n",
    "    tasks_processed = 0\n",
    "    \n",
    "    # 收集处理结果\n",
    "    results = []\n",
    "    \n",
    "    # 在任务队列里先放入所需要加工的任务\n",
    "    for i in range( expected_tasks):\n",
    "        task_queue.put(f\"task_{i}\")\n",
    "    \n",
    "    # 在任务队列后添加足够的终止信号（每个进程会消耗掉一个）。这里可以用multiprocessing.Event代替更好\n",
    "    # 这个方式某种情况下可能导致进程无法终结的问题？\n",
    "    for _ in range(pool_size):\n",
    "        task_queue.put(\"TERMINATE\")\n",
    "\n",
    "    # 创建并启动进程池\n",
    "    pool = Pool(\n",
    "        processes = pool_size,\n",
    "        initializer = worker_process,\n",
    "        initargs = (task_queue, result_queue)\n",
    "    )\n",
    "    \n",
    "    while tasks_processed < expected_tasks:\n",
    "        result = result_queue.get()\n",
    "        tasks_processed += 1\n",
    "        \n",
    "        if 'error' in result:\n",
    "            print(f\"Error from worker {result['worker']} processing {result['task']}: {result['error']}\")\n",
    "        else:\n",
    "            results.append(result)\n",
    "            # print(f\"Worker {result['worker']} processed {result['task']} → {result['result']}\")\n",
    "    \n",
    "    # 等待所有进程完成\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # print(f\"Processed {len(results)} tasks successfully\")\n",
    "    print(f\"Final results: {results}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running subprocess 0\n",
      "STDOUT: Final results: [{'worker': 3, 'result': 358975780942431332, 'task': 'task_0'}, {'worker': 3, 'result': 187842445111551740, 'task': 'task_2'}, {'worker': 2, 'result': 'task_1_KEY2', 'task': 'task_1'}, {'worker': 3, 'result': 8371617324782176147, 'task': 'task_3'}, {'worker': 2, 'result': 'task_4_KEY2', 'task': 'task_4'}]\n",
      "\n",
      " \n",
      "STDERR: \n",
      " \n",
      "Running subprocess 1\n",
      "STDOUT: Final results: [{'worker': 3, 'result': 3337686437969000200, 'task': 'task_0'}, {'worker': 2, 'result': 'task_1_KEY2', 'task': 'task_1'}, {'worker': 3, 'result': -2690394115718592284, 'task': 'task_2'}, {'worker': 2, 'result': 'task_3_KEY2', 'task': 'task_3'}, {'worker': 3, 'result': 3201207304949967064, 'task': 'task_4'}]\n",
      "\n",
      " \n",
      "STDERR: \n",
      " \n",
      "Running subprocess 2\n",
      "STDOUT: Final results: [{'worker': 3, 'result': 5509128965142684649, 'task': 'task_1'}, {'worker': 2, 'result': 'task_0_KEY2', 'task': 'task_0'}, {'worker': 3, 'result': 3581438424763580629, 'task': 'task_2'}, {'worker': 2, 'result': 'task_3_KEY2', 'task': 'task_3'}, {'worker': 3, 'result': 712218674283409547, 'task': 'task_4'}]\n",
      "\n",
      " \n",
      "STDERR: \n",
      " \n",
      "Running subprocess 3\n",
      "STDOUT: Final results: [{'worker': 2, 'result': 'task_0_KEY2', 'task': 'task_0'}, {'worker': 3, 'result': -6329655502754909455, 'task': 'task_2'}, {'worker': 2, 'result': 'task_1_KEY2', 'task': 'task_1'}, {'worker': 3, 'result': -7348275939874455168, 'task': 'task_3'}, {'worker': 2, 'result': 'task_4_KEY2', 'task': 'task_4'}]\n",
      "\n",
      " \n",
      "STDERR: \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "for i in range(4):\n",
    "    print(f\"Running subprocess {i}\")\n",
    "    result = subprocess.run(\n",
    "        [\"python\", \"multiprocessing_script.py\"], \n",
    "        capture_output=True, text=True)\n",
    "    print(\"STDOUT:\", result.stdout)  # 查看任务处理结果\n",
    "    print(\" \")\n",
    "    print(\"STDERR:\", result.stderr)  # 查看是否有错误\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先multiprocessing_script.py程序不会报错error，所以result.stderr始终为“”。multiprocessing_script.py自身就是2个进程的，处理5个任务。偶数id的进程使用 encrypt 模式，拼接任务字符串与密钥。奇数id的进程使用 hash 模式，对任务字符串和密钥进行哈希操作。\n",
    "\n",
    "每次运行脚本时，都会创建一个新的 Python 解释器实例，并独立地执行 multiprocessing_script.py。由于每个子进程中都创建了新的 task_queue 和 result_queue，并且有独立的进程池（进程之间不共享内存），因此每次运行的结果都是独立的。又由于multiprocessing_script.py是多进程并行的，所以输出顺序不稳定且hash值不同。\n",
    "\n",
    "iD1被主进程占用，所以任务分别由id2，id3的进程处理。\n",
    "\n",
    "不稳定的原因：偶数进程有开销小的调度优势（hash很慢），在大部分情况抢占所有任务，奇数就没有要消费的任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.2** 协程\n",
    "    阅读理解下面代码，观察运行的结果，解释结果的原因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张三  准备吃包子啦！,呼吁店小二\n",
      "李四  准备吃包子啦！,呼吁店小二\n",
      "店小二 开始准备做包子啦！\n",
      "做了第1包子，分成两半,你们一人一半\n",
      "包子 1 来了,被 张三 吃了！\n",
      "包子 1 来了,被 李四 吃了！\n",
      "------------------------------------\n",
      "做了第2包子，分成两半,你们一人一半\n",
      "包子 2 来了,被 张三 吃了！\n",
      "包子 2 来了,被 李四 吃了！\n",
      "------------------------------------\n",
      "做了第3包子，分成两半,你们一人一半\n",
      "包子 3 来了,被 张三 吃了！\n",
      "包子 3 来了,被 李四 吃了！\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    " \n",
    "#定义一个消费者，他有名字name\n",
    "#因为里面有yield，本质上是一个生成器\n",
    "def consumer(name): \n",
    "    print(f'{name}  准备吃包子啦！,呼吁店小二')\n",
    "    while True:\n",
    "        baozi=yield  #接收send传的值，并将值赋值给变量baozi\n",
    "        print(f'包子 {baozi+1} 来了,被 {name} 吃了！')\n",
    " \n",
    "#定义一个生产者，生产包子的店家，店家有一个名字name,并且有两个顾客c1 c2\n",
    "def producer(name,c1,c2):\n",
    "    next(c1)  #启动生成器c1\n",
    "    next(c2)  #启动生成器c2\n",
    "    print(f'{name} 开始准备做包子啦！')\n",
    "    for i in range(3):\n",
    "        time.sleep(1)\n",
    "        print(f'做了第{i+1}包子，分成两半,你们一人一半')\n",
    "        c1.send(i)\n",
    "        c2.send(i)\n",
    "        print('------------------------------------')\n",
    " \n",
    "c1=consumer('张三') #把函数变成一个生成器\n",
    "c2=consumer('李四')\n",
    "producer('店小二',c1,c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结果：\n",
    "```python\n",
    "张三  准备吃包子啦！,呼吁店小二\n",
    "\n",
    "李四  准备吃包子啦！,呼吁店小二\n",
    "\n",
    "店小二 开始准备做包子啦！\n",
    "\n",
    "（1s）\n",
    "\n",
    "做了第1包子，分成两半,你们一人一半\n",
    "\n",
    "包子 1 来了,被 张三 吃了！\n",
    "\n",
    "包子 1 来了,被 李四 吃了！\n",
    "\n",
    "------------------------------------\n",
    "\n",
    "（1s）\n",
    "\n",
    "做了第2包子，分成两半,你们一人一半\n",
    "\n",
    "包子 2 来了,被 张三 吃了！\n",
    "\n",
    "包子 2 来了,被 李四 吃了！\n",
    "\n",
    "------------------------------------\n",
    "\n",
    "（1s）\n",
    "\n",
    "做了第3包子，分成两半,你们一人一半\n",
    "\n",
    "包子 3 来了,被 张三 吃了！\n",
    "\n",
    "包子 3 来了,被 李四 吃了！\n",
    "\n",
    "------------------------------------\n",
    "```\n",
    "\n",
    "分析：调用producer后，首先执行两个next，使生成器consumer('张三')， consumer('李四')先运行到第一个yield处，故先输出两行“准备吃包子啦！,呼吁店小二”并等待在producer里接着send，然后producer中继续执行，输出“店小二 开始准备做包子啦！”后在循环中\"输出做了第i+1包子，分成两半,你们一人一半\",并send(i)到这两个consumer的yield处，此时consumer内部baozi被赋值i，输出“包子 i+1 来了,被 张三/李四 吃了！”，并接着执行到下一次yield处等待send。循环三次得到如上结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.3** 正则表达式、网路编程和任务调度\n",
    "\n",
    "    当运行此程序时，最终会输出哪些任务执行信息？说明具体输出顺序和原因\n",
    "\n",
    "    解释正则表达式^(\\d+):(.+)$的作用及其在代码中的具体应用场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server started\n",
      "Connected by ('127.0.0.1', 59923)\n",
      "Scheduled: Task1 at 14:29:29\n",
      "Connected by ('127.0.0.1', 59924)\n",
      "Scheduled: Task2 at 14:29:29\n",
      "Connected by ('127.0.0.1', 59925)\n",
      "Scheduled: Task3 at 14:29:28\n",
      "Executing: Task3 at 14:29:28\n",
      "Executing: Task1 at 14:29:29\n",
      "Executing: Task2 at 14:29:29\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import socket\n",
    "import threading\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "'''\n",
    "TaskScheduler 类\n",
    "功能：实现一个简单的任务调度器，支持添加延迟任务并按时执行。\n",
    "\n",
    "关键点：\n",
    "使用线程锁 (threading.Lock) 保证任务列表的线程安全。\n",
    "使用 datetime 和 timedelta 计算任务的执行时间。\n",
    "使用后台线程 (daemon=True) 持续检查并执行到期的任务。\n",
    "'''\n",
    "           \n",
    "class TaskScheduler:\n",
    "    def __init__(self):\n",
    "        self.tasks = []  # 存储任务列表，每个任务是一个元组 (执行时间, 命令)\n",
    "        self.lock = threading.Lock()  # 线程锁，用于保护任务列表的线程安全\n",
    "    \n",
    "    def add_task(self, delay, command):\n",
    "        with self.lock:  # 加锁，确保线程安全 # 多线程一定要加锁！！！\n",
    "            execute_time = datetime.now() + timedelta(seconds=delay)  # 计算任务的执行时间\n",
    "            self.tasks.append((execute_time, command))  # 将任务添加到任务列表\n",
    "            print(f\"Scheduled: {command} at {execute_time.strftime('%H:%M:%S')}\")  # 打印任务调度信息\n",
    "    \n",
    "    def start(self):\n",
    "        threading.Thread(target=self._run, daemon=True).start()  # 启动后台线程运行任务调度器\n",
    "    \n",
    "    def _run(self):\n",
    "        while True:  # 持续运行(提供服务)\n",
    "            now = datetime.now()  # 获取当前时间\n",
    "            with self.lock:  # 加锁，确保线程安全\n",
    "                due_tasks = [(t, cmd) for t, cmd in self.tasks if t <= now]  # 筛选出到期的任务\n",
    "                self.tasks = [(t, cmd) for t, cmd in self.tasks if t > now]  # 更新任务列表，移除已到期的任务\n",
    "            \n",
    "            for task in due_tasks:  # 遍历并执行到期的任务\n",
    "                print(f\"Executing: {task[1]} at {now.strftime('%H:%M:%S')}\")  # 打印任务执行信息\n",
    "                time.sleep(1)  # 模拟任务执行时间\n",
    "            \n",
    "            time.sleep(0.5)  # 每隔 0.5 秒检查一次任务列表\n",
    "\n",
    "            \n",
    "'''\n",
    "handle_client 函数\n",
    "功能：处理客户端连接，解析客户端发送的命令并添加到任务调度器中。\n",
    "\n",
    "关键点：\n",
    "使用正则表达式 (re.compile) 解析客户端发送的命令。\n",
    "具体命令格式为 ? \n",
    "将解析后的任务添加到任务调度器中。\n",
    "'''\n",
    "def handle_client(conn, scheduler):\n",
    "    pattern = re.compile(r'^(\\d+):(.+)$')  # 正则表达式，匹配具体\"？内容\"\n",
    "    while True:\n",
    "        data = conn.recv(1024).decode()  # 接收客户端发送的数据\n",
    "        if not data:  # 如果数据为空，断开连接\n",
    "            break\n",
    "        match = pattern.match(data.strip())  # 使用正则表达式匹配数据 # strip去掉首尾的连续空格\n",
    "        if match:\n",
    "            delay = int(match.group(1))  # 提取内容1\n",
    "            cmd = match.group(2)  # 提取内容2\n",
    "            scheduler.add_task(delay, cmd)  # 将任务添加到调度器\n",
    "        else:\n",
    "            print(f\"Invalid command: {data}\")  # 如果命令格式无效，打印错误信息\n",
    "\n",
    "'''\n",
    "server 函数\n",
    "功能：启动服务器，监听客户端连接并为每个客户端创建一个线程处理请求。\n",
    "\n",
    "关键点：\n",
    "使用 socket 创建 TCP 服务器。\n",
    "为每个客户端连接创建一个新线程，调用 handle_client 处理客户端请求。\n",
    "'''\n",
    "def server():\n",
    "    scheduler = TaskScheduler()  # 创建任务调度器实例\n",
    "    scheduler.start()  # 启动任务调度器\n",
    "    \n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:  # 创建 TCP 套接字\n",
    "        s.bind(('localhost', 65432))  # 绑定到本地地址和端口\n",
    "        s.listen()  # 开始监听连接\n",
    "        print(\"Server started\")  # 打印服务器启动信息\n",
    "        while True:\n",
    "            conn, addr = s.accept()  # 接受客户端连接\n",
    "            print(f\"Connected by {addr}\")  # 打印客户端地址信息\n",
    "            threading.Thread(target=handle_client, args=(conn, scheduler)).start()  # 为每个客户端创建新线程\n",
    "\n",
    "'''\n",
    "4. 主程序\n",
    "功能：启动服务器并模拟客户端发送任务。\n",
    "\n",
    "关键点：\n",
    "使用 threading.Thread 启动服务器线程。\n",
    "模拟客户端发送任务到服务器。\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    threading.Thread(target=server, daemon=True).start()  # 启动服务器线程\n",
    "    time.sleep(1)  # 等待服务器启动\n",
    "    \n",
    "    # 模拟客户端发送任务\n",
    "    def client(msg):\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:  # 创建客户端套接字\n",
    "            s.connect(('localhost', 65432))  # 连接到服务器\n",
    "            s.sendall(msg.encode())  # 发送任务消息\n",
    "    \n",
    "    client(\"3:Task1\")  # 发送任务 1，\n",
    "    time.sleep(1)\n",
    "    client(\"2:Task2\")  # 发送任务 2，\n",
    "    client(\"1:Task3\")  # 发送任务 3，\n",
    "    \n",
    "    time.sleep(10)  # 保持主线程运行，确保任务执行完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出：\n",
    "\n",
    "Server started\n",
    "\n",
    "Connected by ('127.0.0.1', 59923)\n",
    "\n",
    "Scheduled: Task1 at 14:29:29\n",
    "\n",
    "Connected by ('127.0.0.1', 59924)\n",
    "\n",
    "Scheduled: Task2 at 14:29:29\n",
    "\n",
    "Connected by ('127.0.0.1', 59925)\n",
    "\n",
    "Scheduled: Task3 at 14:29:28\n",
    "\n",
    "Executing: Task3 at 14:29:28\n",
    "\n",
    "Executing: Task1 at 14:29:29\n",
    "\n",
    "Executing: Task2 at 14:29:29\n",
    "\n",
    "\n",
    "创建服务器server线程并启动，并启动了任务调度器scheduler，然后服务器绑定到本地地址和端口并监听。并启动服务器，监听客户端。而在main中，3个客户端连接到服务器（输出Connected）并发送任务消息：\"3:Task1\"，\"2:Task2\"，\"1:Task3\"，此时服务器为每个客户端创建一个线程handle_client并处理任务。然后\n",
    "```python\n",
    "pattern = re.compile(r'^(\\d+):(.+)$')\n",
    "```\n",
    "这行的意思是限定开头（^）到结尾（$），分成两组，第一个为匹配的整数(\":\"前面只有一个整数)，然后匹配\":\"，第二个匹配:后面的内容（即“Task{i}”）,这里目的是在后面的match中找出任务的延长时间delay和任务名称cmd。然后在任务调度器中加入任务（此时时间+延长时间后放入任务列表）。故已启动的任务调度器scheduler会在持续运行的run函数中（每过0.5s就检查一次），对已到期的任务会具体执行（每次任务花费1s）。\n",
    "\n",
    "假设初始时间为0。由于Task1先放入但延迟3s执行（第3s才执行），故先scheduled task1，然后等待1s后放入Task2和Task3（第1s输出），再输出scheduled task2, task3。而Task2延迟2s运行（第3s才执行），Task3延迟1s运行（第2s才执行）,故先execute task3，然后执行这个任务1s后到第3s，这1s依次execute task1, task2（因为FIFO先到先得策略）。\n",
    "\n",
    "优先调度最早到期的策略，到期时间基本相同(<0.5s)则FIFO先到先得策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0.4** 网络爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    阅读下面代码，解释输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling https://www.pku.edu.cn/Crawling https://its.pku.edu.cn/\n",
      "\n",
      "Crawling https://eecs.pku.edu.cn/\n",
      "<RequestsCookieJar[<Cookie JSESSIONID=ADE5B3F0CFF600D6DF4325BFDA31D372 for its.pku.edu.cn/>]>\n",
      "<RequestsCookieJar[]>\n",
      " 北京大学网络服务 - 首页 CARSI 燕云直播 邮箱 门户 客户端 网费充值 CARSI 燕云直播 邮箱 门户 客户端 网费充值 北京大学网络服务 62751023 网络服务网络 信息服务信息 校园卡 高性能计算高性能 机房上机上机 联系我们 计算中心中心 查看IP 忘记密码 断开连接 选择断开 新学期快乐！ More > 新春快乐！ More > 新年快乐！ More > 第四届北京大学信息安全综合能力竞赛 More > 计算中心创新技术手段保障开学典礼网络服务，用心用情提升师生体验 More > More > 通知公告 03-07Gaussian 16、GaussView 6上线正版软件平台new 03-06校园智能体开发团队招募new 02-24关于校园无线网络设备维护的通知new 02-21关于畅春新园光纤改造的通知 新闻动态 03-11计算中心与教务部举行调研交流会 03-06党委宣传部与计算中心举行工作协调推进会 03-01数智化赋能出版，助力教学科研创新——出版社与计算中心开展联学共建活动 12-132024“京华杯”信息安全综合能力竞赛闭幕式暨颁奖典礼举行 2024“京华杯”信息安全综合能力竞赛闭幕式暨颁奖典礼举行 2024年11月29日下午，2024年“京华杯”信息安全综合能力竞赛在北京大学哲学楼201报告厅举行闭幕式暨颁奖典礼。 更多新闻 网络故障报修 CARSI eduroam 桌面防病毒 客户端 漏洞盒子平台 国家信息安全漏洞库 补天漏洞响应平台 教育漏洞报告平台 断开全部连接 关闭 \n",
      " 北京大学信息科学技术学院 X 北京大学 院内门户 English 旧版网站 | 导航 X 学院首页 新闻动态 讲座信息 毕业合影 学院概况 院长寄语 学院简介 相关委员会 机构设置 师资队伍 简介 基础实验教学研究中心 计算机学院 电子学院 集成电路学院 智能学院 教育教学 通知公告 教学信息 特色项目 专业介绍 学生培养 通知公告 学工动态 就业创业 团学组织 品牌活动 规章制度 合作交流 国内合作 国际交流 党群工作 党建动态 工会风采 信科院友 院友工作 院友风采 基金捐赠 English 北京大学“信班”建设指导委员会聘任仪式暨诺贝尔物理学奖获得者天野浩教授学术报告会成功举办 北京大学信息科学技术学院2024年度工作总结大会顺利召开 万象更新，信想事成 | 北京大学信息科学技术学院2025新年晚会 一二·九丨信息科学技术学院代表队蝉联歌会甲组一等奖！ 新闻动态 · 查看更多 · 计算之魂：程序设计语言——王迪老师主讲信科“E席谈”青年学术沙龙第二十七期 2025年3月7日晚，信科“E席谈”青年学术沙龙第二十七期活动在理科一号楼1127学生活动室顺利举办。北京大学计算机学院助理教授、博士生导师王迪老师受邀进行了以“计算之魂：程序设计语言”为主题的分享。学院团委书记吕媛老师参加了本次活动，沙龙由信息科学技术学院学生科学技术协会李唯嘉同学主持。王迪老师讲授讲座伊始，王迪老师先展示了自己围绕计算机程序设计语言的一份“简历”，同时提到了他曾在大学时期选修了数学学院... 2025-03-12 查看详细 攻城狮的寒假日常 01活动回顾各位亲爱的攻城狮们，寒假余额已经耗尽，是时候回顾一下这段自律和钻研交织，学习努力、生活充实的假期打卡之旅了。寒假伊始，攻城狮便推出了为期23天的“攻城狮的寒假日常”打卡活动，分为学习打卡和生活打卡两个板块。在学习打卡中，同学们温故而知新，在假期里仍然保持着良好的学习状态，不断进步。生活打卡里，同学们则用一双发现美的眼睛去看生活中曾经可能被忽略的点点滴滴，人间烟火气，最抚凡人心，从焰火闪... 2025-03-11 查看详细 人民日报 | 当国际大学生比赛出现更多中国面孔 本文原载于《人民日报》2025年03月07日 第10版“还有两题。”管晏如瞥向时钟，离比赛结束不到1小时了。代码写好，还有漏洞，界面跳动着鲜红的报错提示。“剑枫，这题你来搞定。”管晏如扯过草稿纸，“张致，做另一题，我一边写，你一边检查，想想其他解法。”指节在键盘上敲出残影，一旁传来其他队伍的击掌声。最终，有惊无险，两道题都通过了。管晏如、张致、朱剑枫，北京大学信息科学技术学院、图灵班2023级学生，在第49届国... 2025-03-08 查看详细 2025-03-07 北京大学信息科学技术学院举办“花香满院 悦享芳华”三八妇女节主题插花活动 查看详细 2025-03-07 信息科学技术学院学生党支部集体学习全国两会精神 查看详细 通知公告 · 查看更多 · 全部 学院通知 学工通知 教务通知 学工 06 2025-03 “信谈1024”| 活动报名：信科党政班子师生面对面活动【2025年第三期（总第33期）】 学工 25 2025-02 信息科学技术学院2025年春季学期心理咨询预约方式通知 学工 19 2025-02 “信谈1024”| 活动报名：【2025年第二期·学院学生行政办公工作建议专题（总第32期）】信科党政班子师生面对面活动 学工 18 2025-02 信息科学技术学院（本科生学院）学生助理招新通知 学工 06 2025-01 “信谈1024”| 活动报名：【2025年第一期（总第31期）】信科党政班子师生面对面活动 学院 02 2025-01 信息科学技术学院2025年寒假值班表 学院 02 2025-01 信息科学技术学院2025年寒假值班表 学院 19 2024-12 北京大学信息科学技术学院2024年度“创新+”工作站研究项目结项答辩通知 学院 12 2024-12 2025年北京大学“全国优秀中学生信息学冬季体验营”报名通知 学院 24 2024-09 信息科学技术学院2024年十一值班表 学院 01 2024-07 信息科学技术学院2024年暑假值班表 学院 05 2024-06 北京大学信息科学技术学院2024年度“创新+”工作站研究项目立项通知 学工 06 2025-03 “信谈1024”| 活动报名：信科党政班子师生面对面活动【2025年第三期（总第33期）】 学工 25 2025-02 信息科学技术学院2025年春季学期心理咨询预约方式通知 学工 19 2025-02 “信谈1024”| 活动报名：【2025年第二期·学院学生行政办公工作建议专题（总第32期）】信科党政班子师生面对面活动 学工 18 2025-02 信息科学技术学院（本科生学院）学生助理招新通知 学工 06 2025-01 “信谈1024”| 活动报名：【2025年第一期（总第31期）】信科党政班子师生面对面活动 学工 19 2024-12 “信谈1024”|活动报名：【2024年第十六期·期末专题（总第30期）】信科党政班子师生面对面活动 教务 25 2024-10 信息科学技术学院2021级本科毕业论文开题通知 教务 22 2024-10 【转发教务部通知】2025届本科预毕业生图像采集通知 教务 22 2024-10 【转发教务部通知】2024-2025学年秋季学期本科生中期退课通知 教务 04 2024-09 转教务部通知：关于2025届本科毕业生推免资格申请的通知和推免期间办理英文成绩单办法调整的说明 教务 03 2024-07 信息科学技术学院2024届毕业生荣誉学士学位名单 教务 28 2024-06 领取2023年12月四六级成绩报告单 学工动态 · 查看更多 · 攻城狮的寒假日常 信息科学技术学院（本科生学院）举办2024-2025学年春季学期学生助理见面会 校友子女夏令营 | E启未来，扬帆远航：北京大学信息科学技术学院成功举办2024年首届校友子女夏令营活动 信科青协2024冬季“信”心行动期末学业辅导顺利举办！ 电脑小队，暖冬有我——燕园×学院路×新燕园三校区电脑义诊行动顺利举办！ 讲座信息 · 查看更多 · 2025-03-07 周五 北京大学博雅人工智能讲堂第十三期|人工智能与大模型的前世今生：从GPT到DeepSeek的变革之路 主讲人：王立威(北京大学智能学院教授) 时间：2025年3月14日（周五）14:00-16:00 地点：北京大学理教107教室 2025-03-05 周三 信科“E席谈”青年学术沙龙第二十七期|计算之魂：程序设计语言 主讲人：王迪（北京大学计算机学院助理教授、博士生导师） 时间：2025年3月7日（周五）18:40 地点：北京大学理科一号楼1127学生活动室 2025-02-26 周三 信科“E席谈”青年学术沙龙第二十六期|人工智能时代：淘金子还是做铲子？ 主讲人：李萌（北京大学集成电路学院和人工智能研究院双聘助理教授） 时间：2025年2月28日（周五）18:40 地点：北京大学理科一号楼1127 2024-12-30 周一 【年度重磅】诺贝尔物理学奖得主天野浩教授访问北大学术报告会 主讲人：Hiroshi Amano 天野浩（诺贝尔物理学奖得主） 时间：2025年1月14日（周二）10:00 地点：北京大学英杰交流中心阳光厅 2024-12-17 周二 知存讲座第三十六期：处理器芯片塑造智能世界 主讲人：Shuo Li(华为高级技术专家） 时间：2024年12月20日（周五）18:40 地点：北京大学理教107 2024-12-12 周四 陶勇医生给青年学生的眼健康课来啦！ 主讲人：陶勇(首都医科大学附属北京朝阳医院眼科主任医师) 时间：2024年12月16日（周一）18:40-20:30 地点：北京大学二教205 毕业合影 新年晚会 友情链接 教育部 北京大学 北大教务部 基础实验教学研究中心 计算机学院 电子学院 集成电路学院 智能学院 北大信科 快捷入口 院长信箱 招生信息 会议室预订 版权所有©北京大学信息科学技术学院 地址：北京市海淀区颐和园路5号北京大学理科1、2号楼 邮编：100871 \n",
      "<RequestsCookieJar[]>\n",
      " 北京大学 请输入关键字 确定 学生|教职工|校友|访客|招聘|捐赠| 门户网络邮箱燕云直播图书馆医学部领导信箱 北大概况招生学部与院系教育教学科学研究合作交流校园生活 EN 北大是常为新的， 改进的运动的先锋， 要使中国向着好的， 往上的道路走。 北大简介 现任领导 历任领导 组织机构 历史名人信息公开 标识系统 燕园画卷美不胜收， 恰似你将要留在这里的 青春年华。 北京大学欢迎你！ 本科生 研究生 留学生 继续教育 学生奖助信息 暑期学校 勤奋、严谨、 求实、创新。 理学部 信息与工程科学部 人文学部 社会科学学部 经济与管理学部 医学部 跨学科类 深圳研究生院 思想自由、兼容并包。 教育应指导社会， 而非追逐社会。 师资队伍 管理部门 课程设置 海外学习课表查询 华文慕课 教学网 证书验证燕云直播 博学之，审问之， 慎思之，明辨之， 笃行之。 科研成果 研究机构 学术期刊 管理部门 志于道，据于德， 依于仁，游于艺。 国际交流 国内合作 教育基金会 港澳台交流 北京论坛 孔子学院 秋冬春夏， 伴随着四时的运行， 青春和燕园融为一体， 北大成为永恒。 菁菁校园 讲座演出 艺术生活 体育健康 社团活动 档案馆藏 管理服务 校历 EN  北大概况招生学部与院系教育教学科学研究合作交流校园生活 学生|教职工|校友|访客|招聘|捐赠| 门户网络邮箱燕云直播图书馆医学部领导信箱 全国两会召开，北京大学代表委员积极履职尽责、建言献策 东风吹度深研院 群山送青满园春 北大学者书房｜赵诺：治史登峰穷经卷，修心昂首观古今 抽枝吐芽春风劲 悬壶济世杏林丰 招贤迎新海纳百川 百团大战各显神通 红墙映日听燕语 彩画迎春涌暗香  学生|教职工|校友|访客|招聘|捐赠| 门户网络邮箱燕云直播图书馆医学部领导信箱 北大概况招生学部与院系教育教学科学研究合作交流校园生活 EN 北大是常为新的， 改进的运动的先锋， 要使中国向着好的， 往上的道路走。 北大简介 现任领导 历任领导 组织机构 历史名人信息公开 标识系统 燕园画卷美不胜收， 恰似你将要留在这里的 青春年华。 北京大学欢迎你！ 本科生 研究生 留学生 继续教育 学生奖助信息 暑期学校 勤奋、严谨、 求实、创新。 理学部 信息与工程科学部 人文学部 社会科学学部 经济与管理学部 医学部 跨学科类 深圳研究生院 思想自由、兼容并包。 教育应指导社会， 而非追逐社会。 师资队伍 管理部门 课程设置 海外学习课表查询 华文慕课 教学网 证书验证燕云直播 博学之，审问之， 慎思之，明辨之， 笃行之。 科研成果 研究机构 学术期刊 管理部门 志于道，据于德， 依于仁，游于艺。 国际交流 国内合作 教育基金会 港澳台交流 北京论坛 孔子学院 秋冬春夏， 伴随着四时的运行， 青春和燕园融为一体， 北大成为永恒。 菁菁校园 讲座演出 艺术生活 体育健康 社团活动 档案馆藏 管理服务 校历 北大 · 要闻 新闻 校内通知 图片 专题 · 网站 查看更多 中国共产党北京大学第十三次党员 代表大会 了解更多 研究生教育综合改革 了解更多 思政热点面对面 了解更多 新闻网纪念五四百年专题网 了解更多 学术 · 科研 查看更多 北大 · 人物 查看更多 北大 · 人物 查看更多 校园 · 生活 感受流光溢彩的青春 艺术与文化 体育与健康 学生社团 校历 会议讲座 电影演出 通知公告 · 北大声明 查看更多查看更多 媒体北大 更多 · 德赛论坛 更多 合作 · 交流 国际交流 国际交流 国际交流 国际交流 国际交流 国内合作 教育基金会 港澳台交流 北京论坛 查看更多 参观 · 导览 参观预约 建筑一览 校园地图 校园设施 新闻招生招聘捐赠校园地图校历燕园特写未名BBS 版权所有©北京大学 |地址：北京市海淀区颐和园路5号 |邮编：100871 |反馈意见：its@pku.edu.cn |京ICP备05065075号-1 |京公网安备 110402430047 号 关于 · 北大 爱国 进步 民主 科学 1898北大创办时间 114两院院士 51355全日制学生 3784教师 18429本科生 32926研究生 124本科招生专业 311博士招生专业 3006外国留学生 733图书馆藏书（万册） 截止时间：2023.7 北大 · 名人 更多 北大 · 院士 更多 吴汝纶 吴汝纶（1840—1903）安徽桐城人。同治进士。1902年任京师大学堂总教习。 张百熙 张百熙（1847—1907）湖南长沙人。同治进士。 孙家鼐 孙家鼐（1827—1909）安徽寿州（今寿县）人。咸丰状元。曾为光绪皇帝授教。 张亨嘉 张亨嘉（1847—1911）福建侯官（今福州）人。光绪进士。 林 纾 林纾（1852—1924）福建闽县（今福州）人。文学家、翻译家。曾在北京大学任教。能诗，工画，并曾从事小说、戏曲创作。 严 复 严复（1854—1921）福建侯官（今福州）人。思想家、学者、教育家。曾任京师大学堂总监督，1912年出任北京大学首任校长。 蔡元培 蔡元培（1868—1940）浙江绍兴人。民主革命家、教育家、思想家。 钟观光 钟观光（1869—1940）浙江镇海人。生物学家。曾任北京大学等校教授。 葛利普 葛利普（AmadeusWilliamGrabau）(1870—1946)美国威斯康辛州人。地质学家、古生物学家。 梁启超 梁启超（1873—1929）广东新会人。学者、思想家、政治活动家。戊戌维新运动的主要代表人物之一。 钱崇澍 钱崇澍（1883—1965）浙江海宁人。生物学家。学部委员。曾任北京大学等校教授。中国近代植物学的奠基人之一。长期从事植物学的研究和教学工作。 何育杰 何育杰（1882—1939）浙江慈谿人。物理学家。京师大学堂学生。曾任京师大学堂教习、北京大学等校教授。中国近代物理学教育的拓荒者之一。 马寅初 马寅初（1882—1982）浙江嵊县人。经济学家、教育家。学部委员。曾任北京大学教授、教务长、校长、名誉校长等。 鲁 迅 鲁迅（1881—1936）浙江绍兴人。文学家、思想家。曾受聘北京大学讲师、北大研究所国学门委员会委员。 章士钊 章士钊（1881—1973）湖南长沙人。学者、爱国民主人士。曾任北京大学教授兼图书馆主任等。1903年担任《苏报》主笔，宣传反清革命。 马 衡 马衡（1881—1955）浙江鄞县人。金石学家、考古学家。曾任北京大学教授、北大研究所国学门考古研究室主任兼导师。 陈 垣 陈垣（1880—1971）广东新会人。历史学家。学部委员。曾任北京大学教授、北大研究所国学门导师，辅仁大学及北京师范大学校长等。 冯祖荀 冯祖荀（1880—约1940）浙江杭州人。数学家。京师大学堂学生。曾任北京大学教授、系主任。中国近代高等数学教学体系的奠基人之一。 章鸿钊 章鸿钊（1877—1951）浙江湖州人。地质学家。曾任京师大学堂教习、北京大学教授等。中国近代地质学的奠基人之一。 俞同奎 俞同奎（1876—1962）浙江德清人。化学家。早年入京师大学堂学习。曾任京师大学堂教习、北京大学教授、化学系主任等。 马叙伦 马叙伦（1884—1970）浙江杭州人。语言文字学家、教育家。学部委员。曾任北京大学教授。 刘师培 刘师培（1884—1919）江苏仪征人。学者。曾任北京大学教授。1905年参与编辑《国粹学报》，为主要撰稿人。 夏元瑮 夏元瑮（1884—1944）浙江杭州人。物理学家。历任北京大学教授、理科学长、物理系主任等。中国近代物理学教育的拓荒者之一。 萧友梅 萧友梅（1884—1940）广东香山（今中山）人。音乐家。曾任北京大学国文系讲师、音乐研究会导师、音乐传习所教务主任等。 熊十力 熊十力（1884—1968）湖北黄冈人。哲学家。曾任北京大学等校教授。 马文昭 马文昭（1886—1965）河北保定人。医学家。学部委员。曾任北京大学医学院教授、院长，中国解剖学会理事长等。 任鸿隽 任鸿隽（1886—1961）浙江吴兴（今湖州）人。化学家、教育家。曾任北京大学教授，中央研究院总干事兼化学研究所所长等。 沈兼士 沈兼士（1886—1947）浙江吴兴（今湖州）人。语言学家。曾任北京大学国文系教授、北大研究所国学门主任。 秉 志 秉志（1886—1965）河南开封人。满族。生物学家。学部委员。京师大学堂毕业。曾任北京大学教授。中国近代生物学的奠基人之一。 赵柏林 赵柏林，男，1929年4月出生，汉族，辽宁省辽中县人。1952年毕业于清华大学气象系。其后在北京大学物理系及地球物理系任助教和讲师。 了解更多 叶大年 叶大年，男，1939年7月生，汉族，中共党员，民盟盟员，广东省鹤山市人。 了解更多 陶澍 陶澍，男，1950年8月生，汉族，江苏省无锡市人，1977年毕业于北京大学地质地理系，1981年、1984年获美国堪萨斯大学硕士、博士学位。 了解更多 翟中和 翟中和(1930.8.18-2023.2.10)，男，汉族，江苏凓阳人，中共党员。1950-1951年在清华大学学习。 了解更多 吴立新 吴立新，男，1966年9月生，汉族，安徽桐城人。 了解更多 韩济生 韩济生，男，1928年7月生，汉族，中共党员，浙江省萧山市人，生理学家，博士研究生导师。1953年毕业于上海医学院医学系。 了解更多 韩启德 韩启德，男，1945年7月生，汉族，中共党员，九三学社成员，上海市人，病理生理学家。 了解更多 许智宏 许智宏，1942年出生于江苏省无锡市。 了解更多 郑永飞 郑永飞，男，1959年10月生，民族汉，安徽省长丰县人。 了解更多 朱作言 朱作言，男，1941年9月出生，汉族，湖南省澧县人。1965年毕业于北京大学生物系，1980年毕业于中国科学院研究生院。 了解更多 方精云 方精云，男，1959年7月生，汉族，安徽怀宁县人。 了解更多 童坦君 童坦君（1934.8.15-2022.12.25），男，汉族，浙江慈溪人。 了解更多 周忠和 周忠和，男，1965年1月出生，江苏扬州人。 了解更多 张培震 张培震，男，中共党员，1955年12月出生，河南省淮滨县人。 了解更多 北大 · 史苑 讲述北大的历史故事与精神传承 京师大学堂与民国初年的北京大学 北京大学创建于1898年，初名京师大学堂，是中国近代史上第一所国立综合性大学。 五四前后的北京大学 1916年12月，著名教育家、思想家、民主主义革命家蔡元培出任北京大学校长，对北大进行了卓有成效的改革。众多革新人物和学术大师云集北大，倡导民主与科学精神，弘扬爱国与进步思想，促进新思潮的传播和学术的繁荣，使北大成为新文化运动的中心，五四运动的发祥地，传播马克思主义和创建北方地区中国共产党组织的最初基地。这是北大发展史上一个辉煌时期，奠定了北大的光荣革命传统和优良学术传统。 三十年代的北京大学 1927至1929年，北京大学处于动荡之中。奉系军阀攫取北京政权后，实行恐怖统治，悍然杀害了北大教授李大钊等人，把具有民主传统的北京大学视为眼中钉，1927年8月颁令将北京大学与北京其他国立八校合并组成国立京师大学校。 西南联合大学时期的北京大学 1937年7月7日，卢沟桥事变爆发。月底，北平、天津相继陷落。9月，奉教育部令，北京大学与清华大学、南开大学南迁至湘，合组长沙临时大学。 复员后的北京大学 复员后的北京大学迁回北平原校址。1946年7月，新任校长胡适（蒋梦麟辞去北大校长职务后，1945年9月由胡适接替，胡适到任前由傅斯年代行）宣布北大重要教职员人选。1946年7、8月，北大奉教育部令先后接收了北平临时大学补习班一至四分班及第六分班，1947年8月，北洋大学北平部并入北京大学。 新中国成立后十七年的北京大学 1949年10月1日，中华人民共和国成立，北京大学步入新纪元。1949年1月31日，北平和平解放。2月28日，北平军事管制委员会文化接管委员会正式接管北大。5月4日，北大校务委员会成立，汤用彤任主席。 “文化大革命”时期的北京大学 1966年5月16日，中共中央通过了“五·一六通知”，标志着“文化大革命”的开始。在康生及其妻曹轶欧的策划下，哲学系聂元梓等于5月25日贴出了题为《宋硕、陆平、彭珮云在文化革命中究竟干些什么？》的大字报，诬陷、攻击北京大学党委和北京市委。6月1日，中央人民广播电台根据毛泽东主席的批示，全文播发了这张大字报。当晚，华北局派驻北京大学工作组进校。 改革开放时期的北京大学 1976年10月，中共中央一举粉碎“四人帮”，结束了十年“文革”动乱。党和政府对北京大学十分关心，邓小平等中央领导同志多次接见校领导，对北大工作作出重要指示。北京大学遵照党中央拨乱反正的方针，积极开展对教育界“两个估计”的批判；踊跃参加实践是检验真理唯一标准问题的大讨论... 步入21世纪的北京大学 创建世界一流大学是北京大学面向21世纪提出的宏伟规划，是世纪之初指导北京大学各项建设的纲领。在国家“211工程”和“985工程”建设经费的支持下，北大以创建世界一流大学为目标，坚持“追求真理、追求卓越、培养人才、繁荣学术、服务人民、造福社会”的理念... 了解更多北大史苑 档案 · 馆藏 了解北大的风物 风骨 风范 校史馆 地质博物馆 生物标本馆 赛克勒博物馆 档案馆 数据 人物 史苑 馆藏 首页 北大概况 北大简介现任领导历任领导组织机构历史名人信息公开标识系统 招生 本科生研究生留学生继续教育学生奖助信息暑期学校 学部与院系 理学部信息与工程科学部人文学部社会科学学部经济与管理学部医学部跨学科类深圳研究生院 教育教学 师资队伍管理部门课程设置海外学习课表查询华文慕课教学网证书验证燕云直播 科学研究 科研成果研究机构学术期刊管理部门 合作交流 国际交流国内合作教育基金会港澳台交流北京论坛孔子学院 校园生活 菁菁校园讲座演出艺术生活体育健康社团活动档案馆藏管理服务校历 EN   \n"
     ]
    }
   ],
   "source": [
    "import requests                # 用于发送HTTP请求\n",
    "from bs4 import BeautifulSoup  # 用于解析HTML文档\n",
    "import re                      # 用于正则表达式操作\n",
    "import threading               # 用于多线程编程\n",
    "\n",
    "# 定义需要爬取的URL列表\n",
    "urls = [\"https://www.pku.edu.cn/\", \"https://its.pku.edu.cn/\", \"https://eecs.pku.edu.cn/\"]\n",
    "\n",
    "# 定义爬取函数\n",
    "def crawl(url):\n",
    "    print(f\"Crawling {url}\")  # 打印当前正在爬取的URL\n",
    "    response = requests.get(url)  # 发送HTTP GET请求，获取网页内容\n",
    "    response.encoding = response.apparent_encoding  # 根据网页内容自动设置编码\n",
    "    html = response.text  # 获取网页的HTML内容\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')  # 使用BeautifulSoup解析HTML文档\n",
    "\n",
    "    cookies = response.cookies  # 获取服务器返回的Cookies\n",
    "    print(cookies)  # 打印Cookies\n",
    "\n",
    "    # 将Cookies写入文件\n",
    "    with open('cookies.txt', 'a') as f:  # 以追加模式打开文件\n",
    "        f.write(url + ': ' + str(cookies) + '\\n')  # 将URL和对应的Cookies写入文件\n",
    "\n",
    "    # 提取网页中的纯文本内容，并去除多余的空格\n",
    "    text = re.sub(r'\\s+', ' ', soup.get_text())  # 使用正则表达式具体做了？\n",
    "    print(text)  # 打印提取的文本内容\n",
    "\n",
    "    # 将提取的文本内容写入文件\n",
    "    with open('text.txt', 'a') as f:  # 以追加模式打开文件\n",
    "        f.write(text + '\\n')  # 将文本内容写入文件\n",
    "\n",
    "# 创建线程列表，每个线程负责爬取一个URL\n",
    "threads = [threading.Thread(target=crawl, args=(url, )) for url in urls]\n",
    "\n",
    "# 启动所有线程\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "# 等待所有线程完成\n",
    "for t in threads:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出：\n",
    "\n",
    "cookies.txt:\n",
    "```txt\n",
    "https://www.pku.edu.cn/: <RequestsCookieJar[]>\n",
    "\n",
    "https://eecs.pku.edu.cn/: <RequestsCookieJar[]>\n",
    "\n",
    "https://its.pku.edu.cn/: <RequestsCookieJar[<Cookie JSESSIONID=0517C73EC9920A46CC66E1AF00520E0E for its.pku.edu.cn/>]>\n",
    "```\n",
    "text.txt：\n",
    "很长不复制了。\n",
    "\n",
    "分析：\n",
    "\n",
    "爬虫多线程地爬到\"https://www.pku.edu.cn/\", \"https://its.pku.edu.cn/\", \"https://eecs.pku.edu.cn/\"这三个url上，然后每个线程中发送HTTP GET请求后获取网页的HTML内容，再用用BeautifulSoup解析赋值给soup。\n",
    "\n",
    "首先打印服务器的cookie（response.cookies）,并在\n",
    "```python\n",
    "with open('cookies.txt', 'a') as f\n",
    "```\n",
    "中把这些cookie追加地写入文件cookies.txt（即如果文件已经存在，文件指针将会放在文件的结尾，新的内容将会被写入到已有内容之后，故依次输出url（顺序不稳定，因为这是多线程的并行））。然后\n",
    "```python\n",
    "text = re.sub(r'\\s+', ' ', soup.get_text())\n",
    "```\n",
    "把soup的文本内容中的连续的 空格或换行或制表符等空白字符 替换成一个空格（使输出结果更有可读性），并同理输出并追加地写入文件text.txt。最后等待所有线程结束。\n",
    "\n",
    "（注：由如果不加锁的话可能出现一个线程的部分数据与另一个线程的部分数据交错写入文件。只是这里write的内容短所以没有出现。）\n",
    "\n",
    "print是原子操作，但是可能会交织地输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一部分 基础练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.1** 进程的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting multiprocessing_script_task1_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multiprocessing_script_task1_1.py\n",
    "#导入模块\n",
    "import multiprocessing\n",
    "import time\n",
    " \n",
    "#创建进程调用函数\n",
    "def work1(interval):\n",
    "\tprint('执行work1')\n",
    "\ttime.sleep(interval)\n",
    "\tprint('end work1')\n",
    " \n",
    "def work2(interval):\n",
    "\tprint('执行work2')\n",
    "\ttime.sleep(interval)\n",
    "\tprint('end work2')\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "\tprint('执行主进程')\n",
    "\t#代码填空：创建进程对象\n",
    "\tp1=multiprocessing.Process(target = work1, args = (3, ))\n",
    "\tp2=multiprocessing.Process(target = work2, args = (1, ))\n",
    "\t#代码填空：启动进程\n",
    "\tp1.start()\n",
    "\tp2.start()\n",
    "\tp1.join()\n",
    "\tp2.join()\n",
    "\tprint('主进程结束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    [\"python\", \"multiprocessing_script_task1_1.py\"], \n",
    "    capture_output=True, text=True)\n",
    "assert \"执行主进程\" in result.stdout\n",
    "assert \"执行work1\" in result.stdout\n",
    "assert \"执行work2\" in result.stdout\n",
    "assert \"end work1\" in result.stdout\n",
    "assert \"end work2\" in result.stdout\n",
    "assert \"主进程结束\" in result.stdout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2** 进程池"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting multiprocessing_script_task1_2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multiprocessing_script_task1_2.py\n",
    "import multiprocessing\n",
    "\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 代码填空：创建一个进程池，进程数为4\n",
    "    with multiprocessing.Pool(4) as pool:\n",
    "        results = [pool.apply_async(square, (i,)) for i in range(5)]\n",
    "        output = [res.get() for res in results]\n",
    "    print(output)  # 应该输出 [0, 1, 4, 9, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    [\"python\", \"multiprocessing_script_task1_2.py\"], \n",
    "    capture_output=True, text=True)\n",
    "assert result.stdout == \"[0, 1, 4, 9, 16]\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3** 进程消息传递"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting multiprocessing_script_task1_3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile multiprocessing_script_task1_3.py\n",
    "import multiprocessing\n",
    "\n",
    "def consumer(q):\n",
    "    while True:\n",
    "        # 代码填空：从队列中获取数据\n",
    "        item = q.get()\n",
    "        if item == 'STOP':\n",
    "            break\n",
    "        print(f\"消费: {item}\")\n",
    "\n",
    "def producer(q):\n",
    "    for i in range(3):\n",
    "        q.put(f\"产品{i}\")\n",
    "        # 代码填空：向队列中添加数据，内容为\"产品i\"\n",
    "\n",
    "    q.put('STOP')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 代码填空：创建一个队列\n",
    "    q = multiprocessing.Queue()\n",
    "    p1 = multiprocessing.Process(target=producer, args=(q,))\n",
    "    p2 = multiprocessing.Process(target=consumer, args=(q,))\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    [\"python\", \"multiprocessing_script_task1_3.py\"], \n",
    "    capture_output=True, text=True)\n",
    "# print(result.stdout)\n",
    "assert \"消费: 产品0\" in result.stdout\n",
    "assert \"消费: 产品1\" in result.stdout\n",
    "assert \"消费: 产品2\" in result.stdout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.4** 线程的创建和传参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建两个线程，分别计算`x`, `y`的和与积，存入`result`中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "x, y = 3, 4\n",
    "\n",
    "result = {}\n",
    "def worker1(x, y):\n",
    "    result['add'] = x + y\n",
    "    \n",
    "def worker2(x, y):\n",
    "    result['multiply'] = x * y\n",
    "\n",
    "# t1 = ... # TODO: create a thread\n",
    "t1 = threading.Thread(target = worker1, args = (x, y,))\n",
    "# t2 = ... # TODO: create a thread\n",
    "t2 = threading.Thread(target = worker2, args = (x, y,))\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "assert result == {'add': 7, 'multiply': 12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.5** 线程锁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在以下代码用`#######`包含的部分中，在合适的位置添加和应用线程锁，保证`counter`线程安全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "counter = []\n",
    "lock = threading.Lock()  # 创建锁对象\n",
    "\n",
    "##########################################\n",
    "# TODO: add and apply a lock\n",
    "def worker():\n",
    "    with lock:\n",
    "        for _ in range(100):\n",
    "            counter.append(1)\n",
    "            time.sleep(random.random() * 0.01)\n",
    "            counter[-1] += 1\n",
    "##########################################\n",
    "\n",
    "threads = [threading.Thread(target=worker) for _ in range(10)]\n",
    "for t in threads:\n",
    "    t.start()\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "assert counter == [2] * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.6** 生成器与yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received value: 3\n",
      "Received value: 4\n"
     ]
    }
   ],
   "source": [
    "def coroutine_example():\n",
    "    value = yield 0\n",
    "    print(f'Received value: {value}')\n",
    "    assert value == 3\n",
    "    value = yield 1\n",
    "    print(f'Received value: {value}')\n",
    "    yield 5\n",
    "    # 代码填空：返回5\n",
    "\n",
    "c = coroutine_example()\n",
    "next(c)\n",
    "# 代码填空：发送3\n",
    "c.send(3)\n",
    "assert c.send(4) == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.7** 基于协程求平均数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def average():\n",
    "    total = 0.0  #数字的总和\n",
    "    count = 0    #数字的个数\n",
    "    avg = None   #平均值\n",
    "    while True:\n",
    "        ##############################\n",
    "        # 代码填空：接收一个数字，并实现计算平均值的逻辑\n",
    "        value = yield avg\n",
    "        count += 1; total += value\n",
    "        avg = total / count\n",
    "        ##############################\n",
    " \n",
    "#定义一个函数，通过这个函数向average函数发送数值\n",
    "def sender(generator):\n",
    "    print(next(generator))  #启动生成器\n",
    "    assert generator.send(10)==10  # 10\n",
    "    assert generator.send(20)==15  # 15\n",
    "    assert generator.send(30)==20  # 20\n",
    "    assert generator.send(40)==25  # 25\n",
    " \n",
    " \n",
    "g = average()\n",
    "sender(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.8** 正则表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"My phone number is 13345678901 and 15592883746\"\n",
    "# 代码填空：定义正则表达式，匹配手机号码\n",
    "pattern = r'1\\d{10}'\n",
    "matches = re.findall(pattern, text)  \n",
    "assert matches == ['13345678901', '15592883746']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.9** 网络编程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting socket_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile socket_server.py\n",
    "# 服务端\n",
    "import socket\n",
    "\n",
    "# 代码填空：创建服务器套接字，绑定到本地地址，端口9999，监听连接，最大连接数为5\n",
    "server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "host, port = 'localhost', 9999\n",
    "server_socket.bind((host, port))\n",
    "server_socket.listen(5)\n",
    "\n",
    "print(\"服务器已启动，等待连接...\")\n",
    "\n",
    "while True:\n",
    "    # 代码填空：接受客户端连接\n",
    "    client_socket, addr = server_socket.accept()\n",
    "    print(f\"接收到来自 {addr} 的连接\")\n",
    "    \n",
    "    # 代码填空：发送欢迎消息\n",
    "    message = \"欢迎！\"\n",
    "    client_socket.send(message.encode('utf-8'))\n",
    "    \n",
    "    # 关闭连接\n",
    "    client_socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting socket_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile socket_client.py\n",
    "# 客户端\n",
    "import socket\n",
    "\n",
    "# 代码填空：创建客户端套接字\n",
    "client_socket = socket.socket()\n",
    "\n",
    "# 连接到服务器\n",
    "client_socket.connect(('localhost', 9999))\n",
    "\n",
    "# 代码填空：接收欢迎消息\n",
    "message = client_socket.recv(1024).decode('utf-8')\n",
    "print(message)\n",
    "\n",
    "# 关闭连接\n",
    "client_socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欢迎！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# 启动服务器，正确捕获输出\n",
    "server = subprocess.Popen(\n",
    "    [\"python\", \"socket_server.py\"], \n",
    "    stdout=subprocess.PIPE, \n",
    "    stderr=subprocess.PIPE,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# 给服务器一些启动时间\n",
    "time.sleep(1)\n",
    "\n",
    "# 运行客户端\n",
    "client = subprocess.run(\n",
    "    [\"python\", \"socket_client.py\"], \n",
    "    capture_output=True, \n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(client.stdout)\n",
    "server.kill()\n",
    "assert \"欢迎！\" in client.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二部分 进阶练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1** 正则表达式提取参考文献信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    运用正则表达式从下面参考文献中提取作者列表，文章名称，发表时间。\n",
    "    结果存为JSON格式文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "1. Agarwal, Nitin, Ravi Shankar Reddy, Kiran Gvr, and Carolyn Penstein Rosé. 2011. \"Towards multi-document summarization of scientific articles: making interesting comparisons with SciSumm.\" In Proceedings of the Workshop on Automatic Summarization for Different Genres, Media, and Languages, pages 8-15, Portland, Oregon. Association for Computational Linguistics.\n",
    "\n",
    "2. Beltagy, Iz, Kyle Lo, and Arman Cohan. 2019. \"SciBERT: A pretrained language model for scientific text.\" In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3615-3620, Hong Kong, China. Association for Computational Linguistics.\n",
    "\n",
    "3. Beltagy, Iz, Matthew E Peters, and Arman Cohan. 2020. \"Longformer: The long-document transformer.\" arXiv preprint arXiv:2004.05150.\n",
    "\n",
    "4. Bornmann, Lutz, and Rüdiger Mutz. 2015. \"Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references.\" Journal of the Association for Information Science and Technology, 66(11): 2215-2222.\n",
    "\n",
    "5. Brown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. \"Language models are few-shot learners.\" In Advances in Neural Information Processing Systems, volume 33, pages 1877-1901.\n",
    "\n",
    "6. Cohan, Arman, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Seokhwan Kim, Walter Chang, and Nazli Goharian. 2018. \"A discourse-aware attention model for abstractive summarization of long documents.\" In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 615-621, New Orleans, Louisiana. Association for Computational Linguistics.\n",
    "\n",
    "7. Cohan, Arman, Guy Feigenblat, Dayne Freitag, Tirthankar Ghosal, Drahomira Herrmannova, Petr Knoth, Kyle Lo, Philipp Mayr, Michal Shmueli-Scheuer, Anita de Waard, and Lucy Lu Wang. 2022. \"Overview of the third workshop on scholarly document processing.\" In Proceedings of the Third Workshop on Scholarly Document Processing, pages 1-6, Gyeongju, Republic of Korea. Association for Computational Linguistics.\n",
    "\n",
    "8. Cohan, Arman, Sergey Feldman, Iz Beltagy, Doug Downey, and Daniel Weld. 2020. \"SPECTER: Document-level representation learning using citation-informed transformers.\" In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2270-2282, Online. Association for Computational Linguistics.\n",
    "\n",
    "9. DeYoung, Jay, Iz Beltagy, Madeleine van Zuylen, Bailey Kuehl, and Lucy Lu Wang. 2021. \"MS²: Multi-document summarization of medical studies.\" In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7494-7513, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\n",
    "\n",
    "10. Erkan, Günes, and Dragomir R Radev. 2004. \"LexRank: Graph-based lexical centrality as salience in text summarization.\" Journal of artificial intelligence research, 22: 457-479.\n",
    "\n",
    "11. Fabbri, Alexander, Irene Li, Tianwei She, Suyi Li, and Dragomir Radev. 2019. \"Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model.\" In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1074-1084, Florence, Italy. Association for Computational Linguistics.\n",
    "\n",
    "12. Hallgren, Kevin A. 2012. \"Computing inter-rater reliability for observational data: an overview and tutorial.\" Tutorials in quantitative methods for psychology, 8(1): 23-34.\n",
    "\n",
    "13. Hossain, MD Zakir, Ferdous Sohel, Mohd Fairuz Shiratuddin, and Hamid Laga. 2019. \"A comprehensive survey of deep learning for image captioning.\" ACM Computing Surveys, 51(6): 1-36.\n",
    "\n",
    "14. Izacard, Gautier, and Edouard Grave. 2021. \"Leveraging passage retrieval with generative models for open domain question answering.\" In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 874-880, Online. Association for Computational Linguistics.\n",
    "\n",
    "15. Jaidka, Kokil, Christopher Khoo, and Jin-Cheon Na. 2013a. \"Deconstructing human literature reviews–a framework for multi-document summarization.\" In Proceedings of the 14th European Workshop on Natural Language Generation, pages 125-135, Sofia, Bulgaria. Association for Computational Linguistics.\n",
    "\n",
    "16. Jaidka, Kokil, Christopher SG Khoo, and Jin-Cheon Na. 2013b. \"Literature review writing: how information is selected and transformed.\" In Aslib Proceedings, volume 65, pages 303-325.\n",
    "\n",
    "17. Jaidka, Kokil, Christopher SG Khoo, and Jin-Cheon Na. 2019. \"Characterizing human summarization strategies for text reuse and transformation in literature review writing.\" Scientometrics, 121(3): 1563-1582.\n",
    "\n",
    "18. Ji, Ziwei, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, and Pascale Fung. 2022. \"Survey of hallucination in natural language generation.\" ACM Computing Surveys. Just Accepted.\n",
    "\n",
    "19. Jiao, Licheng, and Jin Zhao. 2019. \"A survey on the new generation of deep learning in image processing.\" IEEE Access, 7: 172231-172263.\n",
    "\n",
    "20. Khan, Khalid S, Regina Kunz, Jos Kleijnen, and Gerd Antes. 2003. \"Five steps to conducting a systematic review.\" Journal of the royal society of medicine, 96(3): 118-121.\n",
    "\n",
    "21. Laga, Hamid. 2019. \"A survey on deep learning architectures for image-based depth reconstruction.\" arXiv preprint arXiv:1906.06113.\n",
    "\n",
    "22. Laskar, Md Tahmid Rahman, Enamul Hoque, and Jimmy Xiangji Huang. 2022. \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization.\" Computational Linguistics, 48(2): 279-320.\n",
    "\n",
    "23. LeCun, Yann, Bernhard Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne Hubbard, and Lawrence D Jackel. 1989. \"Backpropagation applied to handwritten zip code recognition.\" Neural computation, 1(4): 541-551.\n",
    "\n",
    "24. Lewis, Mike, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. \"BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.\" In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871-7880, Online. Association for Computational Linguistics.\n",
    "\n",
    "25. Lin, Chin-Yew. 2004. \"ROUGE: A package for automatic evaluation of summaries.\" In Text Summarization Branches Out, pages 74-81, Barcelona, Spain. Association for Computational Linguistics.\n",
    "\n",
    "26. Liu, Ruijun, Yuqian Shi, Changjiang Ji, and Ming Jia. 2019. \"A survey of sentiment analysis based on transfer learning.\" IEEE Access, 7: 85401-85412.\n",
    "\n",
    "27. Lo, Kyle, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel Weld. 2020. \"S2ORC: The semantic scholar open research corpus.\" In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4969-4983, Online. Association for Computational Linguistics.\n",
    "\n",
    "28. Lu, Yao, Yue Dong, and Laurent Charlin. 2020. \"Multi-XScience: A large-scale dataset for extreme multi-document summarization of scientific articles.\" In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8068-8074, Online.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "1. Agarwal, Nitin, Ravi Shankar Reddy, Kiran Gvr, and Carolyn Penstein Rosé. 2011. \"Towards multi-document summarization of scientific articles: making interesting comparisons with SciSumm.\" In Proceedings of the Workshop on Automatic Summarization for Different Genres, Media, and Languages, pages 8-15, Portland, Oregon. Association for Computational Linguistics.\n",
    "\n",
    "2. Beltagy, Iz, Kyle Lo, and Arman Cohan. 2019. \"SciBERT: A pretrained language model for scientific text.\" In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3615-3620, Hong Kong, China. Association for Computational Linguistics.\n",
    "\n",
    "3. Beltagy, Iz, Matthew E Peters, and Arman Cohan. 2020. \"Longformer: The long-document transformer.\" arXiv preprint arXiv:2004.05150.\n",
    "\n",
    "4. Bornmann, Lutz, and Rüdiger Mutz. 2015. \"Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references.\" Journal of the Association for Information Science and Technology, 66(11): 2215-2222.\n",
    "\n",
    "5. Brown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. \"Language models are few-shot learners.\" In Advances in Neural Information Processing Systems, volume 33, pages 1877-1901.\n",
    "\n",
    "6. Cohan, Arman, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Seokhwan Kim, Walter Chang, and Nazli Goharian. 2018. \"A discourse-aware attention model for abstractive summarization of long documents.\" In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 615-621, New Orleans, Louisiana. Association for Computational Linguistics.\n",
    "\n",
    "7. Cohan, Arman, Guy Feigenblat, Dayne Freitag, Tirthankar Ghosal, Drahomira Herrmannova, Petr Knoth, Kyle Lo, Philipp Mayr, Michal Shmueli-Scheuer, Anita de Waard, and Lucy Lu Wang. 2022. \"Overview of the third workshop on scholarly document processing.\" In Proceedings of the Third Workshop on Scholarly Document Processing, pages 1-6, Gyeongju, Republic of Korea. Association for Computational Linguistics.\n",
    "\n",
    "8. Cohan, Arman, Sergey Feldman, Iz Beltagy, Doug Downey, and Daniel Weld. 2020. \"SPECTER: Document-level representation learning using citation-informed transformers.\" In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2270-2282, Online. Association for Computational Linguistics.\n",
    "\n",
    "9. DeYoung, Jay, Iz Beltagy, Madeleine van Zuylen, Bailey Kuehl, and Lucy Lu Wang. 2021. \"MS²: Multi-document summarization of medical studies.\" In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7494-7513, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\n",
    "\n",
    "10. Erkan, Günes, and Dragomir R Radev. 2004. \"LexRank: Graph-based lexical centrality as salience in text summarization.\" Journal of artificial intelligence research, 22: 457-479.\n",
    "\n",
    "11. Fabbri, Alexander, Irene Li, Tianwei She, Suyi Li, and Dragomir Radev. 2019. \"Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model.\" In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1074-1084, Florence, Italy. Association for Computational Linguistics.\n",
    "\n",
    "12. Hallgren, Kevin A. 2012. \"Computing inter-rater reliability for observational data: an overview and tutorial.\" Tutorials in quantitative methods for psychology, 8(1): 23-34.\n",
    "\n",
    "13. Hossain, MD Zakir, Ferdous Sohel, Mohd Fairuz Shiratuddin, and Hamid Laga. 2019. \"A comprehensive survey of deep learning for image captioning.\" ACM Computing Surveys, 51(6): 1-36.\n",
    "\n",
    "14. Izacard, Gautier, and Edouard Grave. 2021. \"Leveraging passage retrieval with generative models for open domain question answering.\" In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 874-880, Online. Association for Computational Linguistics.\n",
    "\n",
    "15. Jaidka, Kokil, Christopher Khoo, and Jin-Cheon Na. 2013a. \"Deconstructing human literature reviews–a framework for multi-document summarization.\" In Proceedings of the 14th European Workshop on Natural Language Generation, pages 125-135, Sofia, Bulgaria. Association for Computational Linguistics.\n",
    "\n",
    "16. Jaidka, Kokil, Christopher SG Khoo, and Jin-Cheon Na. 2013b. \"Literature review writing: how information is selected and transformed.\" In Aslib Proceedings, volume 65, pages 303-325.\n",
    "\n",
    "17. Jaidka, Kokil, Christopher SG Khoo, and Jin-Cheon Na. 2019. \"Characterizing human summarization strategies for text reuse and transformation in literature review writing.\" Scientometrics, 121(3): 1563-1582.\n",
    "\n",
    "18. Ji, Ziwei, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, and Pascale Fung. 2022. \"Survey of hallucination in natural language generation.\" ACM Computing Surveys. Just Accepted.\n",
    "\n",
    "19. Jiao, Licheng, and Jin Zhao. 2019. \"A survey on the new generation of deep learning in image processing.\" IEEE Access, 7: 172231-172263.\n",
    "\n",
    "20. Khan, Khalid S, Regina Kunz, Jos Kleijnen, and Gerd Antes. 2003. \"Five steps to conducting a systematic review.\" Journal of the royal society of medicine, 96(3): 118-121.\n",
    "\n",
    "21. Laga, Hamid. 2019. \"A survey on deep learning architectures for image-based depth reconstruction.\" arXiv preprint arXiv:1906.06113.\n",
    "\n",
    "22. Laskar, Md Tahmid Rahman, Enamul Hoque, and Jimmy Xiangji Huang. 2022. \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization.\" Computational Linguistics, 48(2): 279-320.\n",
    "\n",
    "23. LeCun, Yann, Bernhard Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne Hubbard, and Lawrence D Jackel. 1989. \"Backpropagation applied to handwritten zip code recognition.\" Neural computation, 1(4): 541-551.\n",
    "\n",
    "24. Lewis, Mike, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. \"BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.\" In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871-7880, Online. Association for Computational Linguistics.\n",
    "\n",
    "25. Lin, Chin-Yew. 2004. \"ROUGE: A package for automatic evaluation of summaries.\" In Text Summarization Branches Out, pages 74-81, Barcelona, Spain. Association for Computational Linguistics.\n",
    "\n",
    "26. Liu, Ruijun, Yuqian Shi, Changjiang Ji, and Ming Jia. 2019. \"A survey of sentiment analysis based on transfer learning.\" IEEE Access, 7: 85401-85412.\n",
    "\n",
    "27. Lo, Kyle, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel Weld. 2020. \"S2ORC: The semantic scholar open research corpus.\" In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4969-4983, Online. Association for Computational Linguistics.\n",
    "\n",
    "28. Lu, Yao, Yue Dong, and Laurent Charlin. 2020. \"Multi-XScience: A large-scale dataset for extreme multi-document summarization of scientific articles.\" In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8068-8074, Online.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Agarwal, Nitin, Ravi Shankar Reddy, Kiran Gvr, and Carolyn Penstein Rosé. 2011. \"Towards multi-document summarization of scientific articles: making interesting comparisons with SciSumm.\" In Proceedings of the Workshop on Automatic Summarization for Different Genres, Media, and Languages, pages 8-15, Portland, Oregon. Association for Computational Linguistics.\\n', ' Beltagy, Iz, Kyle Lo, and Arman Cohan. 2019. \"SciBERT: A pretrained language model for scientific text.\" In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3615-3620, Hong Kong, China. Association for Computational Linguistics.\\n', ' Beltagy, Iz, Matthew E Peters, and Arman Cohan. 2020. \"Longformer: The long-document transformer.\" arXiv preprint arXiv:2004.05150.\\n', ' Bornmann, Lutz, and Rüdiger Mutz. 2015. \"Growth rates of modern science: A bibliometric analysis based on the number of publications and cited references.\" Journal of the Association for Information Science and Technology, 66(11): 2215-2222.\\n', ' Brown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. \"Language models are few-shot learners.\" In Advances in Neural Information Processing Systems, volume 33, pages 1877-1901.\\n', ' Cohan, Arman, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Seokhwan Kim, Walter Chang, and Nazli Goharian. 2018. \"A discourse-aware attention model for abstractive summarization of long documents.\" In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 615-621, New Orleans, Louisiana. Association for Computational Linguistics.\\n', ' Cohan, Arman, Guy Feigenblat, Dayne Freitag, Tirthankar Ghosal, Drahomira Herrmannova, Petr Knoth, Kyle Lo, Philipp Mayr, Michal Shmueli-Scheuer, Anita de Waard, and Lucy Lu Wang. 2022. \"Overview of the third workshop on scholarly document processing.\" In Proceedings of the Third Workshop on Scholarly Document Processing, pages 1-6, Gyeongju, Republic of Korea. Association for Computational Linguistics.\\n', ' Cohan, Arman, Sergey Feldman, Iz Beltagy, Doug Downey, and Daniel Weld. 2020. \"SPECTER: Document-level representation learning using citation-informed transformers.\" In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2270-2282, Online. Association for Computational Linguistics.\\n', ' DeYoung, Jay, Iz Beltagy, Madeleine van Zuylen, Bailey Kuehl, and Lucy Lu Wang. 2021. \"MS²: Multi-document summarization of medical studies.\" In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7494-7513, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\\n', ' Erkan, Günes, and Dragomir R Radev. 2004. \"LexRank: Graph-based lexical centrality as salience in text summarization.\" Journal of artificial intelligence research, 22: 457-479.\\n', ' Fabbri, Alexander, Irene Li, Tianwei She, Suyi Li, and Dragomir Radev. 2019. \"Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model.\" In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1074-1084, Florence, Italy. Association for Computational Linguistics.\\n', ' Hallgren, Kevin A. 2012. \"Computing inter-rater reliability for observational data: an overview and tutorial.\" Tutorials in quantitative methods for psychology, 8(1): 23-34.\\n', ' Hossain, MD Zakir, Ferdous Sohel, Mohd Fairuz Shiratuddin, and Hamid Laga. 2019. \"A comprehensive survey of deep learning for image captioning.\" ACM Computing Surveys, 51(6): 1-36.\\n', ' Izacard, Gautier, and Edouard Grave. 2021. \"Leveraging passage retrieval with generative models for open domain question answering.\" In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 874-880, Online. Association for Computational Linguistics.\\n', ' Jaidka, Kokil, Christopher Khoo, and Jin-Cheon Na. 2013a. \"Deconstructing human literature reviews–a framework for multi-document summarization.\" In Proceedings of the 14th European Workshop on Natural Language Generation, pages 125-135, Sofia, Bulgaria. Association for Computational Linguistics.\\n', ' Jaidka, Kokil, Christopher SG Khoo, and Jin-Cheon Na. 2013b. \"Literature review writing: how information is selected and transformed.\" In Aslib Proceedings, volume 65, pages 303-325.\\n', ' Jaidka, Kokil, Christopher SG Khoo, and Jin-Cheon Na. 2019. \"Characterizing human summarization strategies for text reuse and transformation in literature review writing.\" Scientometrics, 121(3): 1563-1582.\\n', ' Ji, Ziwei, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, Andrea Madotto, and Pascale Fung. 2022. \"Survey of hallucination in natural language generation.\" ACM Computing Surveys. Just Accepted.\\n', ' Jiao, Licheng, and Jin Zhao. 2019. \"A survey on the new generation of deep learning in image processing.\" IEEE Access, 7: 172231-172263.\\n', ' Khan, Khalid S, Regina Kunz, Jos Kleijnen, and Gerd Antes. 2003. \"Five steps to conducting a systematic review.\" Journal of the royal society of medicine, 96(3): 118-121.\\n', ' Laga, Hamid. 2019. \"A survey on deep learning architectures for image-based depth reconstruction.\" arXiv preprint arXiv:1906.06113.\\n', ' Laskar, Md Tahmid Rahman, Enamul Hoque, and Jimmy Xiangji Huang. 2022. \"Domain adaptation with pre-trained transformers for query-focused abstractive text summarization.\" Computational Linguistics, 48(2): 279-320.\\n', ' LeCun, Yann, Bernhard Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne Hubbard, and Lawrence D Jackel. 1989. \"Backpropagation applied to handwritten zip code recognition.\" Neural computation, 1(4): 541-551.\\n', ' Lewis, Mike, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. \"BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension.\" In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871-7880, Online. Association for Computational Linguistics.\\n', ' Lin, Chin-Yew. 2004. \"ROUGE: A package for automatic evaluation of summaries.\" In Text Summarization Branches Out, pages 74-81, Barcelona, Spain. Association for Computational Linguistics.\\n', ' Liu, Ruijun, Yuqian Shi, Changjiang Ji, and Ming Jia. 2019. \"A survey of sentiment analysis based on transfer learning.\" IEEE Access, 7: 85401-85412.\\n', ' Lo, Kyle, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel Weld. 2020. \"S2ORC: The semantic scholar open research corpus.\" In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4969-4983, Online. Association for Computational Linguistics.\\n', ' Lu, Yao, Yue Dong, and Laurent Charlin. 2020. \"Multi-XScience: A large-scale dataset for extreme multi-document summarization of scientific articles.\" In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8068-8074, Online.\\n']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# 分割为单独的参考文献条目\n",
    "pattern_split = r'\\n\\d+\\.'\n",
    "references_list = re.split(pattern_split, text)\n",
    "references_list = [ref for ref in references_list if ref.strip()]  # 移除空条目\n",
    "print(references_list)\n",
    "# 提取信息\n",
    "results = []\n",
    "for i, ref in enumerate(references_list):\n",
    "    # 提取作者和年份\n",
    "    author_year_match = re.search(r\"(.+?)\\. (\\d{4}[a-z]?)\", ref) # 分组提取 # 注意2013a.情况\n",
    "    if author_year_match:\n",
    "        authors = author_year_match.group(1).strip()\n",
    "        year = author_year_match.group(2)\n",
    "    else:\n",
    "        authors = \"未找到作者\"\n",
    "        year = \"未找到年份\"\n",
    "    \n",
    "    # 提取文章标题 (引号中的内容)\n",
    "    title_match = re.search(r'\"(.+)\"', ref)\n",
    "    if title_match:\n",
    "        title = title_match.group(1)\n",
    "    else:\n",
    "        title = \"未找到标题\"\n",
    "    results.append({\n",
    "        \"作者列表\": authors,\n",
    "        \"发表时间\": year,\n",
    "        \"文章名称\": title\n",
    "    })\n",
    "\n",
    "# 转换为JSON\n",
    "results_json = json.dumps(results, ensure_ascii = False, indent = 4)\n",
    "\n",
    "# 保存json文件\n",
    "with open('references.json', 'w') as f:\n",
    "    f.write(results_json)\n",
    "\n",
    "with open('references.json', 'r', encoding='utf-8') as f:\n",
    "    loaded_results = json.load(f)\n",
    "assert loaded_results == results\n",
    "assert len(results) == 28\n",
    "assert results[2] == {'作者列表': 'Beltagy, Iz, Matthew E Peters, and Arman Cohan', '发表时间': '2020', '文章名称': 'Longformer: The long-document transformer.'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
